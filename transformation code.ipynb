{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a4311",
   "metadata": {},
   "outputs": [],
   "source": [
    " #pip install pandas-gbq -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d565781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas_gbq\n",
    "import sqlalchemy\n",
    "from faker import Faker\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a53797",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id='pax-5-366517'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f799c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file( r\"C:\\Users\\pothula.yamini\\Downloads\\pax-5-366517-a8e2ac5fe343.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a7d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pothula.yamini\\AppData\\Local\\Temp\\ipykernel_7376\\2517534070.py:2: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  sqlalchemy.engine.url.URL(\n"
     ]
    }
   ],
   "source": [
    "##connection to sql database\n",
    "db = sqlalchemy.create_engine(\n",
    "     sqlalchemy.engine.url.URL(\n",
    "          drivername='mysql+pymysql',\n",
    "          username='root',\n",
    "          password=\"Yamini@kvt12\",\n",
    "          host='35.196.234.121',\n",
    "          database=\"ufh-db\"\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b245f9",
   "metadata": {},
   "source": [
    "### Fetching data from sql database, tranforming and then appending to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1cf8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dim_address():\n",
    "    address_cols = ['address_id', 'address', 'city', 'state', 'pincode']\n",
    "    address = pd.DataFrame(columns=address_cols)\n",
    "    try:\n",
    "        qry = ' Select MAX(Customerid) from ufh_dataset.dim_customer '\n",
    "        max_df1= pd.read_gbq(qry,project_id=project_id,credentials=credentials)\n",
    "        if pd.isna(max_df1.iat[0,0]):\n",
    "            max_cus=0\n",
    "        else:\n",
    "            max_cus=int(max_df1.iat[0,0])\n",
    "\n",
    "    except:\n",
    "        max_cus=0\n",
    "\n",
    "    query1= 'Select * from CUSTOMER_MASTER where Customerid >{} '.format(max_cus)\n",
    "    df_customer= pd.read_sql(query1,con=db)\n",
    "    len1=len(df_customer)\n",
    "\n",
    "    try :\n",
    "        qry= ' Select MAX(Address_id) from ufh_dataset.dim_address '\n",
    "        max_df2= pd.read_gbq(qry,project_id=project_id,credentials=credentials)\n",
    "        if pd.isna(max_df2.iat[0, 0]):\n",
    "            max_add = 0\n",
    "        else:\n",
    "            max_add = int(max_df2.iat[0, 0])\n",
    "    except:\n",
    "        max_add= 0\n",
    "\n",
    "\n",
    "    address_ins = pd.DataFrame(columns = address_cols,index=range(1,len1+1))\n",
    "    for i in range(1, len1+ 1):\n",
    "        address_ins['address_id'][i] = int(max_add) + 1\n",
    "        address_ins['address'][i] = df_customer['Address'][i-1]\n",
    "        address_ins['city'][i] = df_customer['City'][i-1]\n",
    "        address_ins['state'][i] = df_customer['State'][i-1]\n",
    "        address_ins['pincode'][i] = df_customer['Pincode'][i-1]\n",
    "\n",
    "        max_add = int(max_add) + 1\n",
    "    a=address_ins.dtypes\n",
    "    print(\"a\")\n",
    "    address_ins['address_id']=address_ins[\"address_id\"].astype(int)\n",
    "    address_ins['pincode'] = address_ins[\"pincode\"].astype(int)\n",
    "\n",
    "    table= 'ufh_dataset.dim_address'\n",
    "    pandas_gbq.to_gbq(address_ins, table, project_id=project_id,if_exists='replace',credentials=credentials)\n",
    "\n",
    "dim_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ee68681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pothula.yamini\\AppData\\Local\\Temp\\ipykernel_7376\\3027075126.py:27: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  merged_df['end_date']=merged_df['end_date'].astype(np.datetime64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def dim_customer():\n",
    "    dim_customer_cols = ['customerid', 'name', 'address_id', 'start_date', 'end_date']\n",
    "    dim_customer = pd.DataFrame(columns=dim_customer_cols)\n",
    "    try:\n",
    "        qry = ' Select MAX(Customerid) from ufh_dataset.dim_customer '\n",
    "        max_df1= pd.read_gbq(qry,project_id=project_id,credentials=credentials)\n",
    "        if pd.isna(max_df1.iat[0,0]):\n",
    "            max_cus=0\n",
    "        else:\n",
    "            max_cus=int(max_df1.iat[0,0])\n",
    "\n",
    "    except:\n",
    "        max_cus=0\n",
    "\n",
    "    query1 = 'Select * from CUSTOMER_MASTER where Customerid >{} '.format(max_cus)\n",
    "    df_customer= pd.read_sql(query1,con=db)\n",
    "    len1 = len(df_customer)\n",
    "\n",
    "    query2 = 'Select * from ufh_dataset.dim_address '\n",
    "    address = pd.read_gbq(query2, project_id=project_id, credentials=credentials)\n",
    "    merged_df = pd.merge(df_customer, address, left_on=['Address','City', 'State', 'Pincode'],right_on=['address', 'city', 'state', 'pincode'], how='left')\n",
    "    merged_df.drop(columns= ['Address','City','State','Pincode','address',\"city\",\"state\",\"pincode\"],inplace=True)\n",
    "    merged_df.rename(columns={\"Update_timestamp\": 'start_time'}, inplace=True)\n",
    "    merged_df['end_date'] = pd.to_datetime(date(2100, 12, 31), errors='ignore')\n",
    "    merged_df['end_date']=merged_df['end_date'].astype(np.datetime64)\n",
    "    print('a')\n",
    "    table = 'ufh_dataset.dim_customer'\n",
    "    pandas_gbq.to_gbq(merged_df, table, project_id=project_id, if_exists='replace', credentials=credentials)\n",
    "    return max_cus\n",
    "\n",
    "max_cus=dim_customer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de2e8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def dim_order():\n",
    "    try:\n",
    "        qry = ' Select MAX(Orderid) from ufh_dataset.dim_order '\n",
    "        max_df1 = pd.read_gbq(qry, project_id=project_id, credentials=credentials)\n",
    "        if pd.isna(max_df1.iat[0,0]):\n",
    "            max_order = 0\n",
    "        else:\n",
    "            max_order = int(max_df1.iat[0,0])\n",
    "\n",
    "    except:\n",
    "        max_order = 0\n",
    "\n",
    "    query= 'Select * from ORDER_DETAILS where Orderid > {}'.format(max_order)\n",
    "    df_order=pd.read_sql(query,con=db)\n",
    "    df_order.drop(columns=['Customerid'])\n",
    "    table='ufh_dataset.dim_order'\n",
    "    pandas_gbq.to_gbq(df_order, table, project_id=project_id, if_exists='replace', credentials=credentials)\n",
    "    return max_order\n",
    "max_order=dim_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfb50fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def f_order_details(max_order):\n",
    "    qry1='''select * from ORDER_ITEMS where Orderid in (select distinct Orderid from ORDER_DETAILS where Order_status = 'In_progress' and Orderid>{} )'''.format(max_order)\n",
    "    order_items=pd.read_sql(qry1,con=db)\n",
    "    qry2 = 'Select * from ORDER_DETAILS where Orderid > {}'.format(max_order)\n",
    "    df_order = pd.read_sql(qry2, con=db)\n",
    "    delivered_order=  df_order.where(df_order['Order_status']=='Delivered').dropna()\n",
    "    order_details= pd.merge(order_items,delivered_order,on=\"Orderid\")\n",
    "    order_details.drop(columns=['Customerid','Order_status'],inplace=True)\n",
    "    order_details.rename(columns={\"Order_status_update_timestamp\": 'order_delivery_timestamp'}, inplace=True)\n",
    "    table='ufh_dataset.f_order_details'\n",
    "    pandas_gbq.to_gbq(order_details, table, project_id=project_id, if_exists='replace', credentials=credentials)\n",
    "    return order_details\n",
    "\n",
    "f_order=f_order_details(max_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60498ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fact_daily_orders_transform(max_order,max_cus,f_order):\n",
    "    fields = ['customerid', 'orderid', 'order_received_timestamp', 'order_delivery_timestamp', 'pincode',\n",
    "              'order_amount', 'item_count', 'order_delivery_time_seconds']\n",
    "    fact_daily_orders = pd.DataFrame(columns=fields)\n",
    "\n",
    "    qry= 'Select * from ORDER_DETAILS where Orderid > {}'.format(max_order)\n",
    "    order_details= pd.read_sql(qry,con=db)\n",
    "    qry2= 'Select * from CUSTOMER_MASTER where Customerid > {}'.format(max_cus)\n",
    "    customer_details= pd.read_sql(qry2,con=db)\n",
    "    qry3='Select * from PRODUCT_MASTER '\n",
    "    product_details=pd.read_sql(qry3,con=db)\n",
    "\n",
    "    received_df = order_details.where(order_details['Order_status'] == 'Received').dropna()[\n",
    "        ['Customerid', 'Orderid', 'Order_status_update_timestamp']]\n",
    "    delivered_df = order_details.where(order_details['Order_status'] == 'Delivered').dropna()[\n",
    "        ['Customerid', 'Orderid', 'Order_status_update_timestamp']]\n",
    "    merged_df = pd.merge(received_df, delivered_df, on=['Customerid', 'Orderid'], how='left')\n",
    "    merged_df.rename(columns={'Order_status_update_timestamp_x': 'order_received_timestamp',\n",
    "                            'Order_status_update_timestamp_y': 'order_delivery_timestamp'}, inplace=True)\n",
    "    merged_df['order_delivery_time_seconds'] = pd.to_datetime(\n",
    "        merged_df['order_delivery_timestamp']) - pd.to_datetime(merged_df['order_received_timestamp'])\n",
    "    merged_df['order_delivery_time_seconds'] = pd.to_timedelta(merged_df['order_delivery_time_seconds']).view(np.int64) / 1e9\n",
    "\n",
    "    merged_df = pd.merge(merged_df, customer_details, on=['Customerid'], how='left')\n",
    "    merged_df.drop(['Name', 'Address', 'City', 'State', 'Update_timestamp'],inplace=True,axis=1)\n",
    "\n",
    "    cost_df = pd.merge(f_order, product_details, on='Productid', how='left')\n",
    "    cost_df['Quantity']= cost_df[\"Quantity\"].map(int)\n",
    "    cost_df['order_amount'] = cost_df.Quantity *cost_df.Rate\n",
    "    cost_df.drop(['Productcode', 'Productname', 'Sku', 'Isactive'], inplace=True,axis=1)\n",
    "\n",
    "    amount_df = cost_df[['Orderid', 'order_amount']]\n",
    "\n",
    "    amount_df = amount_df.groupby('Orderid').sum()\n",
    "    amount_df.reset_index(level=0,inplace=True)\n",
    "    quantity_per_order = cost_df[['Orderid', 'Quantity']]\n",
    "    quantity_per_order = quantity_per_order.groupby('Orderid').sum()\n",
    "    quantity_per_order.reset_index(level=0,inplace=True)\n",
    "    merged_df['Orderid']=merged_df[\"Orderid\"].map(str)\n",
    "    merged_df[\"Orderid\"]=merged_df['Orderid'].astype(float).astype(int)\n",
    "    merged_df = pd.merge(merged_df, amount_df, on='Orderid', how='left')\n",
    "    fact_daily_orders = pd.merge(merged_df, quantity_per_order, on='Orderid', how='left')\n",
    "    fact_daily_orders.rename(columns={'Quantity': 'item_count'}, inplace=True)\n",
    "    fact_daily_orders.fillna(0, inplace=True)\n",
    "    cols=['Customerid',\"item_count\"]\n",
    "    for i in cols:\n",
    "        fact_daily_orders[i]=fact_daily_orders[i].astype(float).astype(int)\n",
    "    cols1=['order_received_timestamp','order_delivery_timestamp','order_delivery_time_seconds','Pincode','order_amount']\n",
    "    table='ufh_dataset.fact_daily_orders'\n",
    "    pandas_gbq.to_gbq(fact_daily_orders, table, project_id=project_id, if_exists='replace', credentials=credentials)\n",
    "    print(\"A\")\n",
    "\n",
    "\n",
    "fact_daily_orders_transform(max_order,max_cus,f_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09ae42b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pothula.yamini\\AppData\\Local\\Temp\\ipykernel_7376\\2267353113.py:17: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  prod_ins['end_date'] = prod_ins['end_date'].astype(np.datetime64)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def dim_product():\n",
    "    try:\n",
    "        qry = ' Select MAX(Productid) from ufh_dataset.dim_product '\n",
    "        max_df1= pd.read_gbq(qry,project_id=project_id,credentials=credentials)\n",
    "        if pd.isna(max_df1.iat[0,0]):\n",
    "            max_prod=0\n",
    "        else:\n",
    "            max_prod=int(max_df1.iat[0,0])\n",
    "\n",
    "    except:\n",
    "        max_prod=0\n",
    "    qry2= 'select * from PRODUCT_MASTER where Productid > {}'.format(max_prod)\n",
    "    prod_ins=pd.read_sql(qry2,con=db)\n",
    "\n",
    "    prod_ins['start_date'] = datetime.now().date()\n",
    "    prod_ins['end_date'] = pd.to_datetime(date(2100, 12, 31), errors='ignore')\n",
    "    prod_ins['end_date'] = prod_ins['end_date'].astype(np.datetime64)\n",
    "    prod_ins['start_date'] = prod_ins['start_date'].astype(np.datetime64)\n",
    "\n",
    "    table='ufh_dataset.dim_product'\n",
    "    pandas_gbq.to_gbq(prod_ins,table, project_id=project_id, if_exists='replace', credentials=credentials)\n",
    "dim_product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019d747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26db93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29401e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fead163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b0384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8674941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d86eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
